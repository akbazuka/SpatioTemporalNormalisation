{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpatioTemporalModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tsl.nn.blocks.encoders import RNN\n",
        "from tsl.nn.blocks.decoders import GCNDecoder\n",
        "from tsl.nn.blocks.encoders.tcn import TemporalConvNet\n",
        "from tsl.nn.base.embedding import StaticGraphEmbedding\n",
        "from tsl.nn.blocks.decoders.mlp_decoder import MLPDecoder\n",
        "from tsl.nn.layers.graph_convs.diff_conv import DiffConv\n",
        "from tsl.nn.layers.graph_convs.dense_spatial_conv import SpatialConvOrderK\n",
        "from tsl.nn.blocks.encoders import ConditionalBlock\n",
        "from tsl.nn.utils.utils import get_layer_activation\n",
        "from tsl.nn.ops.ops import Lambda\n",
        "from einops.layers.torch import Rearrange\n",
        "from einops import rearrange\n",
        "from einops import repeat\n",
        "import import_ipynb\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import import_ipynb\n",
        "import SpatioTemporalNorm as SpatioTemporalNorm"
      ],
      "metadata": {
        "id": "tGmKD5hRRBe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeThenSpaceModel(torch.nn.Module):\n",
        "    \"\"\"TimeThenSpaceModel: https://github.com/TorchSpatiotemporal/tsl/blob/main/examples/notebooks/a_gentle_introduction_to_tsl.ipynb\n",
        "    \n",
        "    A simple model with a RNN encoder and a nonlinear GCN readout.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Input size.\n",
        "        hidden_size (int): Channels in the hidden layers.\n",
        "        rnn_layers (int): Number of hidden layers passed to the RNN encoder.\n",
        "        gcn_layers (int): Number of layers in the GCN decoder.\n",
        "        horizon (int): Forecasting horizon.\n",
        "        norm (str, optional): Normalization strategy.\n",
        "        caller_class (SpatioTemporalNormExperiment, optional): caller class to store norm weights\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 rnn_layers,\n",
        "                 gcn_layers,\n",
        "                 horizon,\n",
        "                 norm=\"united\", \n",
        "                 caller_class=None):\n",
        "        super(TimeThenSpaceModel, self).__init__()\n",
        "\n",
        "        self.input_encoder = torch.nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        self.encoder = RNN(input_size=hidden_size,\n",
        "                hidden_size=hidden_size,\n",
        "                n_layers=rnn_layers)\n",
        "        \n",
        "        self.norm = SpatioTemporalNorm.SpatioTemporalNorm(norm_type=norm, \n",
        "            in_channels=hidden_size, caller_class=caller_class)\n",
        "\n",
        "        self.decoder = GCNDecoder(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            output_size=input_size,\n",
        "            horizon=horizon,\n",
        "            n_layers=gcn_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # x: [batches steps nodes channels]\n",
        "        x = self.input_encoder(x)\n",
        "\n",
        "        #Normalize the input before passing into the encoder\n",
        "        x = self.norm(x)\n",
        "        x = self.encoder(x, return_last_state=True)\n",
        "\n",
        "        return self.decoder(x, edge_index, edge_weight)\n"
      ],
      "metadata": {
        "id": "0ztjNoAbPK9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TCNModel(torch.nn.Module):\n",
        "    \"\"\"TCNModel: https://torch-spatiotemporal.readthedocs.io/en/latest/_modules/tsl/nn/models/tcn_model.html#TCNModel\n",
        "\n",
        "    A simple Causal Dilated Temporal Convolutional Network for multi-step forecasting.\n",
        "    Learned temporal embeddings are pooled together using dynamics weights.\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Input size.\n",
        "        hidden_size (int): Channels in the hidden layers.\n",
        "        ff_size (int): Number of units in the hidden layers of the decoder.\n",
        "        output_size (int): Output channels.\n",
        "        horizon (int): Forecasting horizon.\n",
        "        kernel_size (int): Size of the convolutional kernel.\n",
        "        n_layers (int): Number of TCN blocks.\n",
        "        exog_size (int): Size of the exogenous variables.\n",
        "        readout_kernel_size (int, optional): Width of the readout kernel size.\n",
        "        resnet (bool, optional): Whether to use residual connections.\n",
        "        dilation (int): Dilation coefficient of the convolutional kernel.\n",
        "        activation (str, optional): Activation function. (default: `relu`)\n",
        "        n_convs_layer (int, optional): Number of temporal convolutions in each layer. (default: 2)\n",
        "        gated (bool, optional): Whether to used the GatedTanH activation function. (default: `False`)\n",
        "        norm (str, optional): Normalization strategy.\n",
        "        caller_class (SpatioTemporalNormExperiment, optional): caller class to store norm weights\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 ff_size,\n",
        "                 output_size,\n",
        "                 horizon,\n",
        "                 kernel_size,\n",
        "                 n_layers,\n",
        "                 exog_size,\n",
        "                 readout_kernel_size=1,\n",
        "                 resnet=True,\n",
        "                 dilation=1,\n",
        "                 activation='relu',\n",
        "                 n_convs_layer=2,\n",
        "                 dropout=0.,\n",
        "                 gated=False,\n",
        "                 norm=\"united\",\n",
        "                 caller_class=None):\n",
        "        super(TCNModel, self).__init__()\n",
        "\n",
        "        if exog_size > 0:\n",
        "            self.input_encoder = ConditionalBlock(input_size=input_size,\n",
        "                                                  exog_size=exog_size,\n",
        "                                                  output_size=hidden_size,\n",
        "                                                  dropout=dropout,\n",
        "                                                  activation=activation)\n",
        "        else:\n",
        "            self.input_encoder = torch.nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        layers = []\n",
        "        self.receptive_field = 0\n",
        "        for i in range(n_layers):\n",
        "            layers.append(torch.nn.Sequential(\n",
        "                SpatioTemporalNorm.SpatioTemporalNorm(norm_type=norm, \n",
        "                    in_channels=hidden_size, caller_class=caller_class),\n",
        "                TemporalConvNet(input_channels=hidden_size,\n",
        "                                hidden_channels=hidden_size,\n",
        "                                kernel_size=kernel_size,\n",
        "                                dilation=dilation,\n",
        "                                gated=gated,\n",
        "                                activation=activation,\n",
        "                                exponential_dilation=True,\n",
        "                                n_layers=n_convs_layer,\n",
        "                                causal_padding=True)\n",
        "                )\n",
        "            )\n",
        "        self.convs = torch.nn.ModuleList(layers)\n",
        "        self.resnet = resnet\n",
        "        activation_layer = get_layer_activation(activation=activation)\n",
        "\n",
        "        self.readout = torch.nn.Sequential(\n",
        "            Lambda(lambda x: x[:, -readout_kernel_size:]),\n",
        "            Rearrange('b s n c -> b n (c s)'),\n",
        "            torch.nn.Linear(hidden_size * readout_kernel_size, ff_size * horizon),\n",
        "            activation_layer(),\n",
        "            torch.nn.Dropout(dropout),\n",
        "            Rearrange('b n (c h) -> b h n c ', c=ff_size, h=horizon),\n",
        "            torch.nn.Linear(ff_size, output_size),\n",
        "        )\n",
        "        self.window = readout_kernel_size\n",
        "        self.horizon = horizon\n",
        "\n",
        "    def forward(self, x, u=None, **kwargs):\n",
        "        # x: [b s n c]\n",
        "        # u: [b s (n) c]\n",
        "        if u is not None:\n",
        "            if u.dim() == 3:\n",
        "                u = rearrange(u, 'b s f -> b s 1 f')\n",
        "            x = self.input_encoder(x, u)\n",
        "        else:\n",
        "            x = self.input_encoder(x)\n",
        "        for conv in self.convs:\n",
        "            x = x + conv(x) if self.resnet else conv(x)\n",
        "\n",
        "        return self.readout(x)\n"
      ],
      "metadata": {
        "id": "Hje9RNurPcrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GWNETModel(torch.nn.Module):\n",
        "    \"\"\"TSL GraphWaveNetModel: https://torch-spatiotemporal.readthedocs.io/en/latest/_modules/tsl/nn/models/stgn/graph_wavenet_model.html?highlight=norm#\n",
        "    \n",
        "    Graph WaveNet Model from Wu et al., ”Graph WaveNet for Deep Spatial-Temporal Graph Modeling”, IJCAI 2019\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Size of the input.\n",
        "        exog_size (int): Size of the exogenous variables.\n",
        "        hidden_size (int): Number of units in the hidden layer.\n",
        "        ff_size (int): Number of units in the hidden layers of the nonlinear readout.\n",
        "        output_size (int): Number of output channels.\n",
        "        n_layers (int): Number of GraphWaveNet blocks.\n",
        "        horizon (int): Forecasting horizon.\n",
        "        temporal_kernel_size (int): Size of the temporal convolution kernel.\n",
        "        spatial_kernel_size (int): Order of the spatial diffusion process.\n",
        "        learned_adjacency (bool): Whether to consider an additional learned adjacency matrix.\n",
        "        n_nodes (int, optional): Number of nodes in the input graph. Only needed if `learned_adjacency` is `True`.\n",
        "        emb_size (int, optional): Number of features in the node embeddings used for graph learning.\n",
        "        dilation (int, optional): Dilation of the temporal convolutional kernels.\n",
        "        dilation_mod (int, optional): Length of the cycle for the dilation coefficient.\n",
        "        dropout (float, optional): Dropout probability.\n",
        "        norm (str, optional): Normalization strategy.\n",
        "        caller_class (SpatioTemporalNormExperiment, optional): caller class to store norm weights\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 exog_size,\n",
        "                 hidden_size,\n",
        "                 ff_size,\n",
        "                 output_size,\n",
        "                 n_layers,\n",
        "                 horizon,\n",
        "                 temporal_kernel_size,\n",
        "                 spatial_kernel_size,\n",
        "                 learned_adjacency,\n",
        "                 n_nodes=None,\n",
        "                 emb_size=8,\n",
        "                 dilation=2,\n",
        "                 dilation_mod=2,\n",
        "                 dropout=0.,\n",
        "                 norm=\"united\",\n",
        "                 caller_class=None):\n",
        "        super(GWNETModel, self).__init__()\n",
        "\n",
        "        if learned_adjacency:\n",
        "            assert n_nodes is not None\n",
        "            self.source_embeddings = StaticGraphEmbedding(n_nodes, emb_size)\n",
        "            self.target_embeddings = StaticGraphEmbedding(n_nodes, emb_size)\n",
        "        else:\n",
        "            self.register_parameter('source_embedding', None)\n",
        "            self.register_parameter('target_embedding', None)\n",
        "\n",
        "        self.input_encoder = torch.nn.Linear(input_size + exog_size, hidden_size)\n",
        "\n",
        "        temporal_conv_blocks = []\n",
        "        spatial_convs = []\n",
        "        skip_connections = []\n",
        "        norms = []\n",
        "        receptive_field = 1\n",
        "        for i in range(n_layers):\n",
        "            d = dilation ** (i % dilation_mod)\n",
        "            temporal_conv_blocks.append(TemporalConvNet(\n",
        "                input_channels=hidden_size,\n",
        "                hidden_channels=hidden_size,\n",
        "                kernel_size=temporal_kernel_size,\n",
        "                dilation=d,\n",
        "                exponential_dilation=False,\n",
        "                n_layers=1,\n",
        "                causal_padding=False,\n",
        "                gated=True\n",
        "            )\n",
        "            )\n",
        "\n",
        "            spatial_convs.append(DiffConv(in_channels=hidden_size,\n",
        "                                          out_channels=hidden_size,\n",
        "                                          k=spatial_kernel_size))\n",
        "\n",
        "            skip_connections.append(torch.nn.Linear(hidden_size, ff_size))\n",
        "            norms.append(SpatioTemporalNorm.SpatioTemporalNorm(norm_type=norm, \n",
        "                in_channels=hidden_size, caller_class=caller_class))            #Define which Normalisation Layers to use here\n",
        "            receptive_field += d * (temporal_kernel_size - 1)\n",
        "        self.tconvs = torch.nn.ModuleList(temporal_conv_blocks)\n",
        "        self.sconvs = torch.nn.ModuleList(spatial_convs)\n",
        "        self.skip_connections = torch.nn.ModuleList(skip_connections)\n",
        "        self.norms = torch.nn.ModuleList(norms)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        self.receptive_field = receptive_field\n",
        "\n",
        "        dense_sconvs = []\n",
        "        if learned_adjacency:\n",
        "            for _ in range(n_layers):\n",
        "                dense_sconvs.append(\n",
        "                    SpatialConvOrderK(input_size=hidden_size,\n",
        "                                      output_size=hidden_size,\n",
        "                                      support_len=1,\n",
        "                                      order=spatial_kernel_size,\n",
        "                                      include_self=False,\n",
        "                                      channel_last=True)\n",
        "                )\n",
        "        self.dense_sconvs = torch.nn.ModuleList(dense_sconvs)\n",
        "        self.readout = torch.nn.Sequential(torch.nn.ReLU(),\n",
        "                                     MLPDecoder(input_size=ff_size,\n",
        "                                                hidden_size=2 * ff_size,\n",
        "                                                output_size=output_size,\n",
        "                                                horizon=horizon,\n",
        "                                                activation='relu'))\n",
        "\n",
        "    def get_learned_adj(self):\n",
        "        logits = F.relu(self.source_embeddings() @ self.target_embeddings().T)\n",
        "        adj = torch.softmax(logits, dim=1)\n",
        "        return adj\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None, u=None, **kwargs):\n",
        "        # x: [batches, steps, nodes, channels] -> [batches, channels, nodes, steps]\n",
        "\n",
        "        if u is not None:\n",
        "            if u.dim() == 3:\n",
        "                u = repeat(u, 'b s c -> b s n c', n=x.size(-2))\n",
        "            x = torch.cat([x, u], -1)\n",
        "\n",
        "        if self.receptive_field > x.size(1):\n",
        "            # pad temporal dimension\n",
        "            x = F.pad(x, (0, 0, 0, 0, self.receptive_field - x.size(1), 0))\n",
        "\n",
        "        if len(self.dense_sconvs):\n",
        "            adj_z = self.get_learned_adj()\n",
        "\n",
        "        x = self.input_encoder(x)\n",
        "\n",
        "        out = torch.zeros(1, x.size(1), 1, 1, device=x.device)\n",
        "        for i, (tconv, sconv, skip_conn, norm) in enumerate(\n",
        "                zip(self.tconvs, self.sconvs, self.skip_connections, self.norms)):\n",
        "            res = x\n",
        "            # temporal conv\n",
        "            x = tconv(x)\n",
        "            # residual connection -> out\n",
        "            out = skip_conn(x) + out[:, -x.size(1):]\n",
        "            # spatial conv\n",
        "            xs = sconv(x, edge_index, edge_weight)\n",
        "            if len(self.dense_sconvs):\n",
        "                x = xs + self.dense_sconvs[i](x, adj_z)\n",
        "            else:\n",
        "                x = xs\n",
        "            x = self.dropout(x)\n",
        "            # residual connection -> next layer\n",
        "            x = x + res[:, -x.size(1):]\n",
        "            x = norm(x)\n",
        "\n",
        "        return self.readout(out)"
      ],
      "metadata": {
        "id": "PhWFC0cBNMrJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}